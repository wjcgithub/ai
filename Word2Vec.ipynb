{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wjcgithub/ai/blob/main/Word2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDjdWIER5Whn"
      },
      "source": [
        "import gensim\n",
        "from gensim.models import word2vec\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMDDtNF-5cKU",
        "outputId": "2f9069fe-e697-4b82-f6c3-94b1dbbb7803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "!wget -P /root/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-18 15:52:00--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.97.141\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.97.141|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘/root/input/GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  16.5MB/s    in 98s     \n",
            "\n",
            "2019-08-18 15:53:39 (16.1 MB/s) - ‘/root/input/GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXY84zUO8KTP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "0040d866-4696-4e29-ecb1-dd470e099767"
      },
      "source": [
        "EMBEDDING_FILE = '/root/input/GoogleNews-vectors-negative300.bin.gz'\n",
        "word_vectors = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o1a3Y1d8uCQ"
      },
      "source": [
        "v_apple = word_vectors[\"apple\"]\n",
        "v_mango = word_vectors[\"mango\"]\n",
        "print(v_apple.shape)\n",
        "print(v_mango.shape)\n",
        "cosine_similarity([v_mango],[v_apple])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSrGB8Wo9mE8"
      },
      "source": [
        "import numpy as np\n",
        "def odd_one_out(words):\n",
        "\n",
        "    all_word_vectors = [word_vectors[w] for w in words]\n",
        "    avg_vector = np.mean(all_word_vectors,axis=0)\n",
        "    #print(avg_vector.shape)\n",
        "\n",
        "    odd_one_out = None\n",
        "    min_similarity = 1.0\n",
        "\n",
        "    for w in words:\n",
        "        sim = cosine_similarity([word_vectors[w]],[avg_vector])\n",
        "        if sim < min_similarity:\n",
        "            min_similarity = sim\n",
        "            odd_one_out = w\n",
        "\n",
        "        print(\"Similairy btw %s and avg vector is %.2f\"%(w,sim))\n",
        "\n",
        "    return odd_one_out\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amP_ZhNKcoNF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "1b9cdde6-c91c-40dc-9f83-8bf937ff68ee"
      },
      "source": [
        "pred=[]\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "dfx = pd.read_csv('https://raw.githubusercontent.com/shankygupta79/GoogleCollabFiles/master/OddOne.csv').values\n",
        "for i in range(4,8):\n",
        "    a=dfx[i]\n",
        "    a=a.reshape(-1)\n",
        "    pred.append(odd_one_out(a))\n",
        "\n",
        "\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(300,)\n",
            "Similairy btw India and avg vector is 0.41\n",
            "Similairy btw football and avg vector is 0.70\n",
            "Similairy btw hockey and avg vector is 0.76\n",
            "Similairy btw cricket and avg vector is 0.80\n",
            "Similairy btw swimming and avg vector is 0.57\n",
            "(300,)\n",
            "Similairy btw who and avg vector is 0.54\n",
            "Similairy btw why and avg vector is 0.81\n",
            "Similairy btw what and avg vector is 0.79\n",
            "Similairy btw where and avg vector is 0.67\n",
            "Similairy btw is and avg vector is 0.47\n",
            "(300,)\n",
            "Similairy btw on and avg vector is 0.66\n",
            "Similairy btw in and avg vector is 0.72\n",
            "Similairy btw over and avg vector is 0.64\n",
            "Similairy btw their and avg vector is 0.60\n",
            "Similairy btw was and avg vector is 0.54\n",
            "(300,)\n",
            "Similairy btw India and avg vector is 0.79\n",
            "Similairy btw Australia and avg vector is 0.71\n",
            "Similairy btw Japan and avg vector is 0.79\n",
            "Similairy btw Russia and avg vector is 0.74\n",
            "Similairy btw China and avg vector is 0.82\n",
            "['India', 'is', 'was', 'Australia']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGQjeHVD-OxZ"
      },
      "source": [
        "## 2. Word Analogies Task\n",
        "man -> woman ::     prince -> princess\n",
        "\n",
        "italy -> italian ::     spain -> spanish\n",
        "\n",
        "india -> delhi ::     japan -> tokyo\n",
        "\n",
        "man -> woman ::     boy -> girl\n",
        "\n",
        "small -> smaller ::     large -> larger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5amEl8e-WWG"
      },
      "source": [
        "def predict_word(a,b,c,word_vectors):\n",
        "    \"\"\"Accepts a triad of words, a,b,c and returns d such that a is to b : c is to d\"\"\"\n",
        "    a,b,c = a.lower(),b.lower(),c.lower()\n",
        "\n",
        "    # similarity |b-a| = |d-c| should be max\n",
        "    max_similarity = -100\n",
        "\n",
        "    d = None\n",
        "\n",
        "    words = word_vectors.vocab.keys()\n",
        "\n",
        "    wa,wb,wc = word_vectors[a],word_vectors[b],word_vectors[c]\n",
        "\n",
        "    #to find d s.t similarity(|b-a|,|d-c|) should be max\n",
        "\n",
        "    for w in words:\n",
        "        if w in [a,b,c]:\n",
        "            continue\n",
        "\n",
        "        wv = word_vectors[w]\n",
        "        sim = cosine_similarity([wb-wa],[wv-wc])\n",
        "\n",
        "        if sim > max_similarity:\n",
        "            max_similarity = sim\n",
        "            d = w\n",
        "\n",
        "    return d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18tVPrWb-k2z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dbd6977c-91de-4a71-a25c-5e181111cdbb"
      },
      "source": [
        "triad_2 = (\"man\",\"woman\",\"prince\")\n",
        "predict_word(*triad_2,word_vectors)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'princess'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-E5fLwA-yJv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "db673810-d5e3-4a95-b348-fe83d97e5f39"
      },
      "source": [
        "#Inbuilt\n",
        "word_vectors.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.7118192911148071)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    }
  ]
}